{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PdUPGB2o96cg",
        "outputId": "c8128775-d4a1-4d02-9026-0e2d805d8469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied log(1+x) transformation to the target variable 'y'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,393</span> (44.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,393\u001b[0m (44.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,393</span> (44.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,393\u001b[0m (44.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 1.6104 - root_mean_squared_error: 1.1289 - val_loss: 0.1808 - val_root_mean_squared_error: 0.4252 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1396 - root_mean_squared_error: 0.3735 - val_loss: 0.1189 - val_root_mean_squared_error: 0.3449 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.1265 - root_mean_squared_error: 0.3556 - val_loss: 0.1072 - val_root_mean_squared_error: 0.3275 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1186 - root_mean_squared_error: 0.3444 - val_loss: 0.1003 - val_root_mean_squared_error: 0.3168 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1118 - root_mean_squared_error: 0.3343 - val_loss: 0.1012 - val_root_mean_squared_error: 0.3181 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1088 - root_mean_squared_error: 0.3299 - val_loss: 0.1056 - val_root_mean_squared_error: 0.3249 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1063 - root_mean_squared_error: 0.3260 - val_loss: 0.0979 - val_root_mean_squared_error: 0.3128 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.1001 - root_mean_squared_error: 0.3163 - val_loss: 0.0891 - val_root_mean_squared_error: 0.2986 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0985 - root_mean_squared_error: 0.3138 - val_loss: 0.0939 - val_root_mean_squared_error: 0.3064 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0970 - root_mean_squared_error: 0.3113 - val_loss: 0.0871 - val_root_mean_squared_error: 0.2951 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0923 - root_mean_squared_error: 0.3038 - val_loss: 0.0821 - val_root_mean_squared_error: 0.2865 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0911 - root_mean_squared_error: 0.3018 - val_loss: 0.0801 - val_root_mean_squared_error: 0.2831 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0884 - root_mean_squared_error: 0.2972 - val_loss: 0.0835 - val_root_mean_squared_error: 0.2889 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0871 - root_mean_squared_error: 0.2951 - val_loss: 0.0765 - val_root_mean_squared_error: 0.2766 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0851 - root_mean_squared_error: 0.2918 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2849 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0835 - root_mean_squared_error: 0.2889 - val_loss: 0.0756 - val_root_mean_squared_error: 0.2750 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0827 - root_mean_squared_error: 0.2875 - val_loss: 0.0952 - val_root_mean_squared_error: 0.3086 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0815 - root_mean_squared_error: 0.2855 - val_loss: 0.0770 - val_root_mean_squared_error: 0.2774 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0807 - root_mean_squared_error: 0.2841 - val_loss: 0.0750 - val_root_mean_squared_error: 0.2738 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0792 - root_mean_squared_error: 0.2815 - val_loss: 0.0722 - val_root_mean_squared_error: 0.2687 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0780 - root_mean_squared_error: 0.2793 - val_loss: 0.0703 - val_root_mean_squared_error: 0.2652 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0797 - root_mean_squared_error: 0.2822 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2672 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0751 - root_mean_squared_error: 0.2741 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2583 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0744 - root_mean_squared_error: 0.2727 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2698 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0750 - root_mean_squared_error: 0.2738 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2699 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0726 - root_mean_squared_error: 0.2695 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2621 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0718 - root_mean_squared_error: 0.2679 - val_loss: 0.0718 - val_root_mean_squared_error: 0.2679 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0722 - root_mean_squared_error: 0.2687 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2481 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0713 - root_mean_squared_error: 0.2669 - val_loss: 0.0661 - val_root_mean_squared_error: 0.2571 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0685 - root_mean_squared_error: 0.2617 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2494 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0684 - root_mean_squared_error: 0.2616 - val_loss: 0.0678 - val_root_mean_squared_error: 0.2604 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0688 - root_mean_squared_error: 0.2622 - val_loss: 0.0718 - val_root_mean_squared_error: 0.2680 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m3055/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0678 - root_mean_squared_error: 0.2603\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0678 - root_mean_squared_error: 0.2603 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0568 - root_mean_squared_error: 0.2383 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2321 - learning_rate: 2.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0536 - root_mean_squared_error: 0.2314 - val_loss: 0.0518 - val_root_mean_squared_error: 0.2275 - learning_rate: 2.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0531 - root_mean_squared_error: 0.2305 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2289 - learning_rate: 2.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2261 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2250 - learning_rate: 2.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0513 - root_mean_squared_error: 0.2264 - val_loss: 0.0510 - val_root_mean_squared_error: 0.2257 - learning_rate: 2.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0512 - root_mean_squared_error: 0.2262 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2254 - learning_rate: 2.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0509 - root_mean_squared_error: 0.2257 - val_loss: 0.0501 - val_root_mean_squared_error: 0.2239 - learning_rate: 2.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0505 - root_mean_squared_error: 0.2247 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2237 - learning_rate: 2.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0493 - root_mean_squared_error: 0.2221 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2232 - learning_rate: 2.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0499 - root_mean_squared_error: 0.2233 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2217 - learning_rate: 2.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0487 - root_mean_squared_error: 0.2207 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2222 - learning_rate: 2.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0508 - root_mean_squared_error: 0.2253 - val_loss: 0.0510 - val_root_mean_squared_error: 0.2258 - learning_rate: 2.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0489 - root_mean_squared_error: 0.2212 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2234 - learning_rate: 2.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0481 - root_mean_squared_error: 0.2194 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2198 - learning_rate: 2.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2199 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2231 - learning_rate: 2.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0489 - root_mean_squared_error: 0.2210 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2220 - learning_rate: 2.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0487 - root_mean_squared_error: 0.2206 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2208 - learning_rate: 2.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0470 - root_mean_squared_error: 0.2168 - val_loss: 0.0503 - val_root_mean_squared_error: 0.2242 - learning_rate: 2.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0479 - root_mean_squared_error: 0.2189 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2187 - learning_rate: 2.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0472 - root_mean_squared_error: 0.2172 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2210 - learning_rate: 2.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0464 - root_mean_squared_error: 0.2153 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2167 - learning_rate: 2.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0479 - root_mean_squared_error: 0.2189 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2173 - learning_rate: 2.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0463 - root_mean_squared_error: 0.2151 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2154 - learning_rate: 2.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0457 - root_mean_squared_error: 0.2137 - val_loss: 0.0503 - val_root_mean_squared_error: 0.2244 - learning_rate: 2.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2143 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2201 - learning_rate: 2.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0461 - root_mean_squared_error: 0.2147 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2150 - learning_rate: 2.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163 - learning_rate: 2.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0463 - root_mean_squared_error: 0.2152 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2188 - learning_rate: 2.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2141 - learning_rate: 2.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0460 - root_mean_squared_error: 0.2145 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2159 - learning_rate: 2.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0464 - root_mean_squared_error: 0.2154 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172 - learning_rate: 2.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0440 - root_mean_squared_error: 0.2098 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2167 - learning_rate: 2.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0450 - root_mean_squared_error: 0.2121 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147 - learning_rate: 2.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m3054/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2145 - learning_rate: 2.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0418 - root_mean_squared_error: 0.2045 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2099 - learning_rate: 4.0000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0421 - root_mean_squared_error: 0.2052 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 4.0000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 4.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0432 - root_mean_squared_error: 0.2078 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 4.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0413 - root_mean_squared_error: 0.2033 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 4.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0424 - root_mean_squared_error: 0.2058 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 4.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m3059/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 4.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2085 - learning_rate: 8.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0417 - root_mean_squared_error: 0.2042 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 8.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2028 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 8.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0412 - root_mean_squared_error: 0.2030 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 8.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2016 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 8.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m3043/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0414 - root_mean_squared_error: 0.2035\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 5e-06.\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0414 - root_mean_squared_error: 0.2035 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 8.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0409 - root_mean_squared_error: 0.2022 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 5.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 5.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0411 - root_mean_squared_error: 0.2026 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 5.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0412 - root_mean_squared_error: 0.2030 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 5.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0417 - root_mean_squared_error: 0.2042 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 5.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0408 - root_mean_squared_error: 0.2020 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 5.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0417 - root_mean_squared_error: 0.2041 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0409 - root_mean_squared_error: 0.2021 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0420 - root_mean_squared_error: 0.2050 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - learning_rate: 5.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2018 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0413 - root_mean_squared_error: 0.2033 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0410 - root_mean_squared_error: 0.2024 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - learning_rate: 5.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0414 - root_mean_squared_error: 0.2035 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - learning_rate: 5.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2017 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - learning_rate: 5.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2028 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2012 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - learning_rate: 5.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0410 - root_mean_squared_error: 0.2024 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - learning_rate: 5.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2011 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082 - learning_rate: 5.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0414 - root_mean_squared_error: 0.2035 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - learning_rate: 5.0000e-06\n",
            "Model training finished.\n",
            "Model saved successfully to 'option_log_price_predictor.keras'\n",
            "\n",
            "Test Set RMSE on Log-Transformed Prices: 0.2112\n",
            "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\n",
            "Using final validation MSE for bias correction: 0.0433\n",
            "\n",
            "RMSE of Biased (uncorrected) Predictions: $32.86\n",
            "RMSE of Corrected Predictions:           $34.76\n",
            "Improvement from correction: -5.78%\n",
            "\n",
            "Sample Predictions (in original dollar scale):\n",
            "        Actual_Price  Predicted_Biased  Predicted_Corrected\n",
            "64928          42.80         48.899979            49.992584\n",
            "129085        175.25        192.544830           196.782715\n",
            "112527        219.40        220.359772           225.206696\n",
            "14956           1.00          0.741737             0.779873\n",
            "61123         340.90        267.244263           273.117767\n",
            "46683           2.20          2.714838             2.796177\n",
            "17346           0.60          0.678473             0.715225\n",
            "13627           1.30          1.010782             1.054810\n",
            "137108        200.85        202.999603           207.466415\n",
            "107980        535.55        545.277588           557.238953\n",
            "143529        414.05        438.585236           448.210449\n",
            "119505        143.60        172.603516           176.404755\n",
            "77342           2.65          2.884976             2.970041\n",
            "8919            0.55          0.544417             0.578233\n",
            "45906         322.75        368.495636           376.586182\n",
            "115401         97.95        110.426804           112.866623\n",
            "42789         806.65        766.515686           783.321289\n",
            "9035         2265.40       2253.560303          2302.926514\n",
            "120859          9.95         10.548052            10.800907\n",
            "12814         359.20        333.808777           341.139771\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# --- 1. Load and Prepare the Data ---\n",
        "df = pd.read_excel('Final_Without_IV.xlsx')\n",
        "X = df.drop('Option_Price_C', axis=1)\n",
        "y = df['Option_Price_C']\n",
        "\n",
        "# --- CHANGED: Apply the log(1+x) transformation to the target variable ---\n",
        "# This helps the model handle the wide range of option prices more effectively.\n",
        "y_log = np.log1p(y)\n",
        "print(\"Applied log(1+x) transformation to the target variable 'y'.\")\n",
        "\n",
        "\n",
        "# --- 2. Split and Scale the Data ---\n",
        "# --- CHANGED: Use y_log for splitting. Keep original y for final comparison. ---\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Keep the original, untransformed y_test for final comparison\n",
        "y_test = y.loc[y_test_log.index]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# --- 3. Build and Compile the Model ---\n",
        "# This part remains the same. The model will now learn to predict the log-price.\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.000005,\n",
        "    verbose=1\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "# --- CHANGED: Train the model on the log-transformed y_train_log ---\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train_log, # Train on log-transformed values\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training finished.\")\n",
        "\n",
        "model.save('option_log_price_predictor.keras')\n",
        "print(\"Model saved successfully to 'option_log_price_predictor.keras'\")\n",
        "\n",
        "\n",
        "# --- 5. Evaluate and Predict ---\n",
        "\n",
        "# First, evaluate the model on the log-transformed test data\n",
        "loss, rmse_log = model.evaluate(X_test_scaled, y_test_log, verbose=0)\n",
        "print(f\"\\nTest Set RMSE on Log-Transformed Prices: {rmse_log:.4f}\")\n",
        "\n",
        "# Make predictions (these will be in the log scale)\n",
        "log_predictions = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "# --- >>> BIAS CORRECTION STARTS HERE <<< ---\n",
        "\n",
        "# --- ADDED: Get the variance of the error (sigma^2) from the validation set ---\n",
        "# The model's loss ('mean_squared_error') on the validation set is the best\n",
        "# estimate of its error variance on unseen data.\n",
        "sigma_sq = history.history['val_loss'][-1]\n",
        "print(f\"\\nUsing final validation MSE for bias correction: {sigma_sq:.4f}\")\n",
        "\n",
        "# --- ADDED: Apply the correction factor to the log predictions ---\n",
        "# This adjusts the prediction from the median to the mean.\n",
        "corrected_log_predictions = log_predictions + 0.5 * sigma_sq\n",
        "\n",
        "# --- CHANGED: Inverse transform both the original and the corrected predictions ---\n",
        "# We'll do this to see the impact of the correction.\n",
        "predictions_biased = np.expm1(log_predictions)\n",
        "predictions_corrected = np.expm1(corrected_log_predictions)\n",
        "\n",
        "# --- CHANGED: Calculate and compare the RMSE for both versions ---\n",
        "rmse_biased = np.sqrt(mean_squared_error(y_test, predictions_biased))\n",
        "rmse_corrected = np.sqrt(mean_squared_error(y_test, predictions_corrected))\n",
        "\n",
        "print(f\"\\nRMSE of Biased (uncorrected) Predictions: ${rmse_biased:.2f}\")\n",
        "print(f\"RMSE of Corrected Predictions:           ${rmse_corrected:.2f}\")\n",
        "\n",
        "improvement = ((rmse_biased - rmse_corrected) / rmse_biased) * 100\n",
        "print(f\"Improvement from correction: {improvement:.2f}%\")\n",
        "\n",
        "# --- >>> BIAS CORRECTION ENDS HERE <<< ---\n",
        "\n",
        "# --- CHANGED: Show comparison with original prices and both prediction types ---\n",
        "results = pd.DataFrame({\n",
        "    'Actual_Price': y_test,\n",
        "    'Predicted_Biased': predictions_biased,\n",
        "    'Predicted_Corrected': predictions_corrected\n",
        "})\n",
        "print(\"\\nSample Predictions (in original dollar scale):\")\n",
        "print(results.head(20))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
